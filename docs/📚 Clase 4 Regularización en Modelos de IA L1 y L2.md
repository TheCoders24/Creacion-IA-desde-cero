隆Genial! Ahora que tienes la tarea clara, vamos a abordar un tema clave para mejorar nuestros modelos y evitar que se ajusten demasiado a los datos de entrenamiento: **la regularizaci贸n**.

---

## ** Clase 4: Regularizaci贸n en Modelos de IA (L1 y L2)**

### **驴Por qu茅 necesitamos regularizaci贸n?**
El **sobreajuste** (overfitting) ocurre cuando un modelo se ajusta demasiado a los datos de entrenamiento, capturando detalles irrelevantes o ruido, en lugar de aprender patrones generales. Esto puede hacer que el modelo tenga un desempe帽o pobre en nuevos datos (datos de prueba o datos reales).

La **regularizaci贸n** es una t茅cnica que penaliza los valores grandes de los par谩metros del modelo para evitar el sobreajuste, promoviendo modelos m谩s simples que generalicen mejor.

### **1. Regularizaci贸n L2 (Ridge)**
La regularizaci贸n **L2** agrega una penalizaci贸n basada en el cuadrado de los par谩metros (pesos del modelo). El t茅rmino penaliza grandes valores de \( w \) (los pesos) para evitar que el modelo se sobreajuste. Es 煤til cuando hay una cantidad significativa de datos y se quiere evitar que el modelo se enfoque demasiado en caracter铆sticas irrelevantes.

La **funci贸n de p茅rdida** con L2 es:
\[
J(w) = \text{MSE} + \lambda \cdot \sum_{i=1}^{n} w_i^2
\]
donde:
- \( \lambda \) es el **hiperpar谩metro de regularizaci贸n**, que controla la fuerza de la penalizaci贸n.
- \( w_i \) son los pesos del modelo.
- \( \text{MSE} \) es el error cuadr谩tico medio.

### **2. Regularizaci贸n L1 (Lasso)**
La regularizaci贸n **L1** agrega una penalizaci贸n basada en el valor absoluto de los par谩metros. Esto tiene el efecto de **eliminar** completamente algunas caracter铆sticas al poner sus pesos en cero, lo que resulta en un modelo m谩s esparso. Es 煤til cuando se cree que algunas caracter铆sticas no son relevantes y se desea una selecci贸n autom谩tica de caracter铆sticas.

La **funci贸n de p茅rdida** con L1 es:
\[
J(w) = \text{MSE} + \lambda \cdot \sum_{i=1}^{n} |w_i|
\]

### **3. Regularizaci贸n ElasticNet**
La **regularizaci贸n ElasticNet** es una combinaci贸n de L1 y L2, que intenta aprovechar lo mejor de ambos mundos. Es 煤til cuando se quiere tanto una penalizaci贸n de los pesos grandes (L2) como la eliminaci贸n de caracter铆sticas irrelevantes (L1).

La **funci贸n de p茅rdida** de ElasticNet es:
\[
J(w) = \text{MSE} + \lambda_1 \cdot \sum_{i=1}^{n} |w_i| + \lambda_2 \cdot \sum_{i=1}^{n} w_i^2
\]
donde \( \lambda_1 \) y \( \lambda_2 \) son los hiperpar谩metros de regularizaci贸n.

---

### **Implementaci贸n de Regularizaci贸n en Descenso del Gradiente (Python)**

Aqu铆 tienes un ejemplo de c贸mo implementar la **regularizaci贸n L2 (Ridge)** en el descenso del gradiente para una regresi贸n lineal:

```python
import numpy as np
import matplotlib.pyplot as plt

# Generar datos de ejemplo (y = 2x + 1)
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 2 * X + 1 + np.random.randn(100, 1)  # Agregar algo de ruido

# Inicializar los par谩metros
w = np.random.randn(1)
b = np.random.randn(1)
learning_rate = 0.01
epochs = 1000
lambda_reg = 0.1  # Hiperpar谩metro de regularizaci贸n L2
m = len(X)

# Funci贸n de costo (MSE + Regularizaci贸n L2)
def compute_cost(X, y, w, b, lambda_reg):
    predictions = X.dot(w) + b
    cost = (1/(2*m)) * np.sum((predictions - y) ** 2) + (lambda_reg / 2) * np.sum(w ** 2)
    return cost

# Descenso del gradiente con regularizaci贸n L2
for epoch in range(epochs):
    # Predicci贸n
    y_pred = X.dot(w) + b
    
    # C谩lculo de gradientes
    dw = (1/m) * np.dot(X.T, (y_pred - y)) + lambda_reg * w  # T茅rmino de regularizaci贸n en dw
    db = (1/m) * np.sum(y_pred - y)
    
    # Actualizaci贸n de par谩metros
    w -= learning_rate * dw
    b -= learning_rate * db
    
    # Imprimir el costo cada 100 iteraciones
    if epoch % 100 == 0:
        print(f'Epoch {epoch}: Cost {compute_cost(X, y, w, b, lambda_reg)}')

# Mostrar la recta ajustada
plt.scatter(X, y)
plt.plot(X, X.dot(w) + b, color='red')
plt.title('Regresi贸n Lineal con Regularizaci贸n L2')
plt.xlabel('X')
plt.ylabel('y')
plt.show()
```

---

### ** Tarea para la pr贸xima clase:**
1. **Investiga sobre la regularizaci贸n L1, L2 y ElasticNet** y c贸mo se ajustan en diferentes modelos.
2. **Prueba el c贸digo de descenso del gradiente** con regularizaci贸n L2, cambiando el valor de \( \lambda \) y observando c贸mo afecta al modelo.
3. **Compara los resultados** entre usar o no regularizaci贸n, y experimenta con diferentes tasas de aprendizaje y 茅pocas.

---
***TAREA DE LA PROXIMA CLASE***

### 1. **Investigar sobre la regularizaci贸n L1, L2 y ElasticNet y c贸mo se ajustan en diferentes modelos**

La **regularizaci贸n** es una t茅cnica fundamental para mejorar la capacidad de generalizaci贸n de los modelos de IA y evitar el sobreajuste (overfitting). Existen diferentes tipos de regularizaci贸n:

#### **L1 (Lasso)**
- **驴Qu茅 hace?**: Agrega una penalizaci贸n a la suma de los valores absolutos de los pesos del modelo.
- **驴C贸mo ayuda?**: L1 tiene la propiedad de "eliminar" caracter铆sticas, ya que algunos de los pesos pueden volverse exactamente cero, lo que lleva a un modelo m谩s simple y m谩s interpretativo.
- **驴D贸nde se usa?**: L1 es 煤til cuando se cree que solo un peque帽o subconjunto de las caracter铆sticas es relevante, ya que autom谩ticamente realiza una selecci贸n de caracter铆sticas.

#### **L2 (Ridge)**
- **驴Qu茅 hace?**: Agrega una penalizaci贸n a la suma de los cuadrados de los pesos del modelo.
- **驴C贸mo ayuda?**: L2 penaliza los pesos grandes, pero no los lleva exactamente a cero. Esto ayuda a evitar que el modelo se enfoque demasiado en caracter铆sticas con valores extremos y hace que el modelo sea m谩s general.
- **驴D贸nde se usa?**: L2 es 煤til cuando hay muchas caracter铆sticas y se desea evitar que alguna de ellas tenga un peso excesivo, pero no se quiere eliminar ninguna.

#### **ElasticNet**
- **驴Qu茅 hace?**: Combina tanto L1 como L2. La idea es usar lo mejor de ambos mundos: la selecci贸n autom谩tica de caracter铆sticas de L1 y la estabilidad de L2.
- **驴C贸mo ayuda?**: ElasticNet es 煤til cuando hay muchas caracter铆sticas correlacionadas entre s铆. L1 puede eliminar algunas de estas caracter铆sticas, pero L2 mantiene el modelo estable y evita el sobreajuste.
- **驴D贸nde se usa?**: Se utiliza cuando se sospecha que tanto la selecci贸n de caracter铆sticas (L1) como la penalizaci贸n de grandes pesos (L2) son necesarias.

---

### 2. **Prueba el c贸digo de descenso del gradiente con regularizaci贸n L2, cambiando el valor de \( \lambda \) y observando c贸mo afecta al modelo**

- **Objetivo**: El valor de \( \lambda \) controla la fuerza de la penalizaci贸n en la regularizaci贸n L2.
  - **Si \( \lambda \) es grande**: El modelo se ver谩 m谩s penalizado por los grandes pesos, lo que reducir谩 la complejidad del modelo y posiblemente lo har谩 menos preciso.
  - **Si \( \lambda \) es peque帽o**: El modelo tendr谩 m谩s libertad para ajustarse a los datos, lo que puede llevar a un sobreajuste si el valor de \( \lambda \) es muy bajo.
  
- **Tarea pr谩ctica**: Ejecutar el c贸digo de descenso del gradiente con regularizaci贸n L2 y variar el valor de \( \lambda \) para ver c贸mo cambia el modelo. Observa c贸mo afecta el costo y el comportamiento de la recta ajustada a los datos.

---

### 3. **Compara los resultados entre usar o no regularizaci贸n, y experimenta con diferentes tasas de aprendizaje y 茅pocas**

- **Comparar resultados con y sin regularizaci贸n**: Esto te permitir谩 observar si la regularizaci贸n mejora la generalizaci贸n del modelo o si en realidad lo hace menos preciso al intentar forzar los pesos a ser peque帽os.
  - **Sin regularizaci贸n**: El modelo puede ajustarse demasiado a los datos de entrenamiento y tener un desempe帽o pobre en datos nuevos.
  - **Con regularizaci贸n**: El modelo deber铆a tener un mejor desempe帽o general en datos no vistos, pero podr铆a perder algo de precisi贸n en los datos de entrenamiento debido a la penalizaci贸n.

- **Tasas de aprendizaje**: La tasa de aprendizaje controla cu谩n r谩pido ajusta el modelo sus par谩metros. Si es demasiado alta, el modelo puede no converger; si es demasiado baja, el entrenamiento ser谩 lento. Experimenta con diferentes valores de la tasa de aprendizaje para ver c贸mo afecta la velocidad de convergencia y la calidad del modelo.

- **pocas**: Son el n煤mero de veces que el modelo pasa por todos los datos de entrenamiento. Si tienes demasiadas 茅pocas, el modelo puede sobreajustarse. Si tienes pocas 茅pocas, el modelo podr铆a no entrenarse lo suficiente. Experimenta con distintas cantidades de 茅pocas para encontrar el punto donde el modelo converge de forma 贸ptima.

---

### **Resumen de lo que debes hacer:**
1. **Investigar** los tres tipos de regularizaci贸n (L1, L2 y ElasticNet) y c贸mo se utilizan en distintos modelos.
2. **Probar el c贸digo de descenso del gradiente con regularizaci贸n L2**, modificando \( \lambda \) y observando su efecto en el modelo.
3. **Comparar los resultados** entre usar regularizaci贸n y no usarla, ajustando tambi茅n la tasa de aprendizaje y las 茅pocas.

---
